import pandas as pd
import numpy as np
from dateutil.relativedelta import relativedelta
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# =========================
# 1) Carregar dados
# =========================
emp = pd.read_csv("empresas_mensal.csv")
trx = pd.read_csv("transacoes_diarias.csv")

# Normalizar nomes possíveis de colunas (id_pgto vs d_pgto)
if "id_pgto" in trx.columns:
    pgto_col = "id_pgto"
elif "d_pgto" in trx.columns:
    pgto_col = "d_pgto"
else:
    raise ValueError("A coluna do pagador não foi encontrada (use id_pgto ou d_pgto).")

rcbe_col = "id_rcbe" if "id_rcbe" in trx.columns else None

# =========================
# 2) Datas & chaves
# =========================
emp["dt_refe"] = pd.to_datetime(emp["dt_refe"])
emp["dt_abrt"] = pd.to_datetime(emp["dt_abrt"])
trx["dt_refe"] = pd.to_datetime(trx["dt_refe"])

emp["ano_mes"] = emp["dt_refe"].dt.to_period("M").astype(str)
trx["ano_mes"] = trx["dt_refe"].dt.to_period("M").astype(str)

# =========================
# 3) Features de EMPRESAS
# =========================

# 3.1 Idade (em anos, no mês de referência de cada linha)
emp["idade_anos"] = (emp["dt_refe"] - emp["dt_abrt"]).dt.days / 365.25
emp["idade_anos"] = emp["idade_anos"].clip(lower=0)

# 3.2 Macro Setor a partir do CNAE (pega os 2 primeiros dígitos numéricos do código)
def extrai_cnae_prefix(ds):
    # tenta achar o prefixo numérico do código (ex.: "47.11-3 - desc" -> 47)
    if pd.isna(ds):
        return np.nan
    s = str(ds)
    # captura primeira sequência de dígitos
    num = ""
    for ch in s:
        if ch.isdigit():
            num += ch
        elif num:  # parou de ler dígitos
            break
    try:
        return int(num[:2]) if num else np.nan
    except:
        return np.nan

def macro_setor(prefix):
    # mapa simplificado por prefixo do CNAE-2
    # ajuste conforme sua realidade
    try:
        p = int(prefix)
    except:
        return "Outros"
    if 1 <= p <= 9:    return "Agro"
    if 10 <= p <= 33:  return "Indústria"
    if 41 <= p <= 43:  return "Construção"
    if 45 <= p <= 47:  return "Comércio"
    if 49 <= p <= 53:  return "Transporte/Armaz."
    if 55 <= p <= 56:  return "Aloj/Aliment."
    if 58 <= p <= 63:  return "Info/Comunic."
    if 64 <= p <= 66:  return "Financeiro"
    if p == 68:        return "Imobiliário"
    if 69 <= p <= 75:  return "Profissionais/Técnicos"
    if 77 <= p <= 82:  return "Serv. Empresas"
    if p == 84:        return "Adm Pública"
    if p == 85:        return "Educação"
    if 86 <= p <= 88:  return "Saúde"
    if 90 <= p <= 93:  return "Arte/Esporte"
    if 94 <= p <= 96:  return "Outros Serviços"
    return "Outros"

emp["cnae_prefix"] = emp["ds_cnae"].apply(extrai_cnae_prefix)
emp["macro_setor"]  = emp["cnae_prefix"].apply(macro_setor)

# 3.3 Rentabilidade = (vl_fatu - vl_sldo) / vl_fatu (seguro p/ zero)
emp["rentabilidade"] = np.where(emp["vl_fatu"] > 0,
                                (emp["vl_fatu"] - emp["vl_sldo"]) / emp["vl_fatu"],
                                0.0)

# 3.4 Crescimento de faturamento (pct_change por empresa)
emp_sorted = emp.sort_values(["ID","dt_refe"]).copy()
emp_sorted["crescimento_fatu"] = emp_sorted.groupby("ID")["vl_fatu"].pct_change().replace([np.inf,-np.inf], np.nan)
# agregados por empresa (média dos últimos 6 meses disponíveis)
emp_sorted["rank_mes"] = emp_sorted.groupby("ID")["dt_refe"].rank(method="first", ascending=True)
emp_last6 = emp_sorted.groupby("ID").tail(6)
emp_agg = (emp_last6.groupby("ID").agg(
    idade_med=("idade_anos","mean"),
    rentab_med=("rentabilidade","mean"),
    fatu_med=("vl_fatu","mean"),
    sldo_med=("vl_sldo","mean"),
    cresc_fatu_med=("crescimento_fatu","mean"),
    macro_setor=("macro_setor", lambda x: x.mode().iloc[0] if len(x.mode())>0 else "Outros")
).reset_index())

# =========================
# 4) Features de TRANSAÇÕES
# =========================

# 4.1 Frequência e ticket médio por mês (por pagador)
freq_mensal = (trx.groupby([pgto_col,"ano_mes"])["vl"]
                  .agg(qtd="count", soma="sum")
                  .reset_index())
freq_agg = (freq_mensal.groupby(pgto_col)
            .agg(freq_med_mensal=("qtd","mean"),
                 ticket_medio=("soma","mean"))  # média da soma/mês (proxy de ticket médio mensal)
            .reset_index()
            .rename(columns={pgto_col:"ID"}))

# 4.2 Sazonalidade: dia da semana e mês
trx["dow"] = trx["dt_refe"].dt.dayofweek  # 0=Seg...6=Dom
trx["mes"] = trx["dt_refe"].dt.month
sazo_dow = (trx.groupby([pgto_col,"dow"])["vl"].count()
            .groupby(level=0).apply(lambda s: (s/s.sum()))
            .reset_index(name="share_dow"))
sazo_mes = (trx.groupby([pgto_col,"mes"])["vl"].count()
            .groupby(level=0).apply(lambda s: (s/s.sum()))
            .reset_index(name="share_mes"))

# agregados simples (pico de dia da semana e pico de mês)
sazo_dow_peak = (sazo_dow.sort_values(["share_dow"], ascending=False)
                 .groupby(pgto_col).head(1)
                 .rename(columns={"dow":"dow_mais_forte","share_dow":"dow_share"})
                 .drop(columns=["share_dow"], errors="ignore"))
sazo_mes_peak = (sazo_mes.sort_values(["share_mes"], ascending=False)
                 .groupby(pgto_col).head(1)
                 .rename(columns={"mes":"mes_mais_forte","share_mes":"mes_share"})
                 .drop(columns=["share_mes"], errors="ignore"))

sazo_peak = (sazo_dow_peak.merge(sazo_mes_peak, on=pgto_col, how="outer")
             .rename(columns={pgto_col:"ID"}))

# 4.3 Recorrência (opcional, se existir id_rcbe)
if rcbe_col:
    parcerias = trx.groupby([pgto_col, rcbe_col])["vl"].count().reset_index(name="qtd")
    rec_por_pagador = (parcerias.groupby(pgto_col)
                       .agg(parceiros_unicos=(rcbe_col,"nunique"),
                            repeticoes=("qtd", lambda s: (s>1).sum()))
                       .reset_index()
                       .rename(columns={pgto_col:"ID"}))
else:
    rec_por_pagador = pd.DataFrame(columns=["ID","parceiros_unicos","repeticoes"])

# =========================
# 5) Juntar features por empresa (ID)
# =========================
feat = (emp_agg.merge(freq_agg, on="ID", how="left")
             .merge(sazo_peak, on="ID", how="left")
             .merge(rec_por_pagador, on="ID", how="left"))

# preencher NaNs razoáveis
for c in ["freq_med_mensal","ticket_medio","parceiros_unicos","repeticoes"]:
    if c in feat.columns:
        feat[c] = feat[c].fillna(0)

# =========================
# 6) Clusters (KMeans)
# =========================
num_cols = ["idade_med","rentab_med","fatu_med","sldo_med","cresc_fatu_med","freq_med_mensal","ticket_medio","parceiros_unicos","repeticoes"]
num_cols = [c for c in num_cols if c in feat.columns]  # caso falte id_rcbe
X = feat[num_cols].replace([np.inf,-np.inf], np.nan).fillna(0.0)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans = KMeans(n_clusters=4, random_state=42, n_init="auto")
feat["cluster"] = kmeans.fit_predict(X_scaled)

# =========================
# 7) Distribuições setoriais
# =========================
# média de faturamento e saldo por macro_setor + contagem de empresas
setorial = (feat.merge(emp[["ID","macro_setor"]].drop_duplicates(), on="ID", how="left")
                 .groupby("macro_setor").agg(
                     empresas=("ID","nunique"),
                     fatu_med=("fatu_med","mean"),
                     sldo_med=("sldo_med","mean")
                 ).reset_index().sort_values("empresas", ascending=False))

# =========================
# 8) Resultados principais
# =========================
print("\n=== Tabela final de features por empresa (amostra) ===")
print(feat.head(10))

print("\n=== Distribuição de clusters ===")
print(feat["cluster"].value_counts())

print("\n=== Distribuição setorial (top) ===")
print(setorial.head(10))
